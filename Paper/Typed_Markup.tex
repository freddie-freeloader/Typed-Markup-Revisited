% Created 2018-03-11 So 21:10
% Intended LaTeX compiler: pdflatex
\documentclass[format=acmsmall, review=true, screen=true]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{listings}

\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\newcommand{\codefigure}[3]{
\begin{figure}
#3
\captionof{figure}{\label{#1}
#2}
\end{figure}
}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
%\acmJournal{TWEB}
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}
%\copyrightyear{2009}
%\acmArticleSeq{9}


% DOI
\acmDOI{}

% Creative Commons is not supported yet...
% $https://github.com/borisveytsman/acmart/issues/77
\setcopyright{none}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}

\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ 
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\ttfamily\small,
  breakatwhitespace=true,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  %captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=none,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  %keywordstyle=\color{blue},       % keyword style
  morekeywords={*,...},            % if you want to add more keywords to the set
  %numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  %numbersep=5pt,                   % how far the line-numbers are from the code
  %numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  %rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  %stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  %title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

% TODO: Figure out the best way to do vertical spacing between paragraphs
\usepackage{parskip}
\setlength{\parskip}{0.5\baselineskip plus2pt minus2pt}

\author{Jonas U. Benn}

\acmPrice{}
\date{\today}
\title[Draft for *HSXML Revisited*]{Draft for *HSXML Revisited*}
\hypersetup{
 pdfauthor={Jonas U. Benn},
 pdftitle={HSXML/Typed Markup Revisited},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.3.50.2 (Org mode 9.1.6)}, 
 pdflang={English}}

\begin{document}


\lstset{language=Haskell}

\maketitle
%\tableofcontents


\section{Introduction}
\label{sec:orgc140eeb}

In the age of digital documents, an author of content is confronted with the
question which document format to choose [when it comes to text].

Since every document format has its advantages, one might not want to commit to
a specific format to soon. A series of blog posts might turn into a book (or at
least a pretty typeset \texttt{pdf}) or an author might want to give the reader the
freedom to read their text on differently sized displays — if the reader has
ever tried to read a paper in \texttt{pdf}-format on an e-book reader, no further
motivation might be needed.

Luckily the problem of decoupling initial text from output seems to be solved by
the rise of markup languages such as Markdown/Commonmark and alike. These type
of documents can be easily [transpiled/converted] into all sorts of output
formats by programs as \texttt{pandoc}.

If the reader has no objections to such a publishing system, they might read no
further and write away their next \emph{format-agnostic} document. But if they are
interested in [bridging the gap between markup and programming languages and/or]
how they can let a type-checker reason about the \emph{well-formedness} of their
document, they may find the findings gathered in this paper worth while.

This paper mostly outlines the ideas of the work on \texttt{HSXML: Typed SXML} and the
underlying idea of \texttt{Finally Tagless Interpreters}.

In short a richly typed representation like \texttt{HSXML} has in our opinion two major
advantages over markup languages such as Markdown/Commonmark et al.:

\begin{enumerate}
\item Guarantee the well-formedness of the document by construction
\item Easy extensibility without loosing the guarantees of 1.
\end{enumerate}

While having these two advantages we still do not want to loose perspective and
be true to our initial goal:

\begin{enumerate}
\item Writing documents that are format agnostic — i.e. observe our source in
different ways
\end{enumerate}

or as described in the Wikipedia-article on \emph{Markup Languages}

\begin{quote}
Descriptive markup

Markup is used to label parts of the document rather than to provide specific
instructions as to how they should be processed. Well-known examples include
\LaTeX{}, HTML, and XML. The objective is to decouple the inherent structure of the
document from any particular treatment or rendition of it. Such markup is often
described as "semantic".
\end{quote}

Oleg Kiselyov might want to argue that such a markup is even \emph{symantic}.

\section{?}
\label{sec:org7537ecb}
\subsection{AST-encoding with Extensible Observers}
\label{sec:org5f9818b}

Pandoc achieves the separation of input and output format by choosing an
Algebraic Data Type as its intermediate representation. We will quickly sketch
why such an encoding leads to an easy extensibility of constructors by looking a
subset of Pandoc's Abstract Syntax Tree and writing some observers for it.

Given the representation (Figure \ref{Pandoc_AST}) we can write \emph{observers}
that interpret this data in different ways (Figure \ref{org0b814ca}). So in the
dimension of observers our encoding is obviously extensible.

Now we can construct a tree in the host language and interpret it in two
different ways:
\begin{lstlisting}
groceryList :: [Block]
groceryList
  = [ Heading 1  [ Str "Grocery list"]
    , BulletList [ Paragraph [Str "1 Banana"]
                 , Paragraph [Str "2 ", Emph [Str "organic"], Str " Apples"]]]

groceryListCM :: CommonMark
groceryListCM = mconcatMap docToCMark groceryList

groceryListLaTeX :: LaTeX
groceryListLaTeX = mconcatMap docToLaTeX groceryList
\end{lstlisting}

We can make our life a bit easier by adding an instance for \texttt{IsString} for our
representation. This injects \texttt{String} automatically into our data types by
applying \texttt{fromString} to it.

\begin{lstlisting}
instance IsString Inline where
  fromString = Str
\end{lstlisting}


Our initial definition is now even more concise:

\begin{lstlisting}
groceryListShort :: [Block]
groceryListShort
  = [ Heading 1  [ "Grocery list"]
    , BulletList [ Paragraph ["1 Banana"]
                 , Paragraph ["2 ", Emph ["organic"], " Apples"] ]]
\end{lstlisting}

\begin{figure}
\begin{lstlisting}
  data Block
  = Paragraph   [Inline] -- ^ Paragraph
  | BulletList  [Block]    -- ^ Bullet list (list of items, each a block)
  | Heading Int [Inline] -- ^ Heading - level (integer) and text (inlines)
  
  data Inline
  = Str String      -- ^ Text (string)
  | EmDash          -- ^ em dash
  | Emph   [Inline] -- ^ Emphasized text (list of inlines)
  | Strong [Inline] -- ^ Strongly emphasized text (list of inlines)
\end{lstlisting}
\captionof{figure}{\label{Pandoc_AST}
This is part of the pandoc AST modulo EmDash}
\end{figure}

\begin{figure}
\begin{lstlisting}
docToCMark :: Block -> CommonMark
docToCMark (Paragraph text)     = mconcatMap inlineToCMark text
docToCMark (BulletList docs)    = addLineBreak $ mconcatMap (mappend "- " . docToCMark) docs
docToCMark (Heading level text) = addLineBreak $ headingPrefix `mappend` mconcatMap inlineToCMark text
 where
  headingPrefix = mconcat $ replicate level "#"

addLineBreak :: CommonMark -> CommonMark
addLineBreak text = text `mappend` "\n"

inlineToCMark :: Inline -> CommonMark
inlineToCMark (Str content)     = fromString content
inlineToCMARK (Emph contents)   = "*" `mappend` mconcatMap inlineToCMark contents `mappend` "*"
inlineToCMARK (Strong contents) = "**" `mappend` mconcatMap inlineToCMark contents `mappend` "**"
inlineToCMARK EmDash            = "---"

docToLaTex :: Block -> LaTeX
...

inlineToLaTex :: Inline -> LaTeX
...
\end{lstlisting}
\captionof{figure}{\label{org0b814ca}
Pandoc-encoding — Markdown Observer}
\end{figure}


\clearpage

\subsection{Extensible Variants}
\label{sec:orgccbaf12}

The encoding works very well, as long as we have foreseen every variant we might
want to create. But as soon as we want to add a new kind of node (e.g. a node
representing the em dash) we are out of luck. Even if we have access to the
original ADT-definition and we could add this new node, this would break all
existing observers that were written for the original ADT.

\subsection{Expression Problem}
\label{sec:orgb21dca4}

To be extensible in the dimension of observers as well as the dimension of the
variants, while still guaranteeing statically their compatibility, is quite a
challenge and one that quite common when writing software. It was named as the
\textbf{Expression Problem} by Wadler [reference] and many solutions have been proposed.

The most prominent solutions — that are right at home in Haskell — are described
in \emph{Data-types a la carte} [reference] and in \emph{Finally Tagless …} [reference].
Kiselyov’s et al. solution to this is — in our opinion — both easy to use and
when used as a DSL for our particular problem, the relationship to S-expressions
becomes quite obvious.


\subsection{Final Tagless Encoding}
\label{sec:org6195637}

Our first attempt to encode our document in the final tagless encoding will not
have the distinction between \texttt{Doc} and \texttt{Inline} — which was enforced by the
Pandoc-encoding. But later we will see that we are able to recover that property
quite easily with great extensibility properties.

The basic idea of the final tagless encoding is as follows:

\begin{itemize}
\item Create a type class that specifies all our constructors in Church encoding
(Figure \ref{First_Step_FT})
\item Parametrize over the return-type and recursive fields of those constructors
(Figure \ref{Second_Step_FT})
\end{itemize}

\begin{figure}
\begin{lstlisting}
data Doc where
  Doc :: String -> Doc

instance Monoid (Doc doc) where
  mappend (Doc doc1) (Doc doc2) = Doc $ doc1 `mappend` doc2
  mempty = Doc mempty

-- Constructors

class Block where
  paragraph  ::        [Doc] -> Doc
  bulletList ::        [Doc] -> Doc
  heading    :: Int -> [Doc] -> Doc

class Inline a where
  emDash ::           Doc
  str    :: String -> Doc
  str = Doc
\end{lstlisting}
\captionof{figure}{\label{First_Step_FT}
First Step FT-encoding}
\end{figure}

\begin{figure}
\begin{lstlisting}
-- DocConstraint defined using ConstraintKinds
type DocConstraint doc = (Monoid doc, IsString doc)

newtype Doc doc = Doc doc

instance DocConstraint doc => -- Have to restrict for the use of 'mempty'
  Monoid (Doc doc) where
  mappend (Doc doc1) (Doc doc2) = Doc $ doc1 `mappend` doc2
  mempty = Doc mempty

-- Constructors

class Block a where
  paragraph  ::        [Doc a] -> Doc a
  bulletList ::        [Doc a] -> Doc a
  heading    :: Int -> [Doc a] -> Doc a

class DocConstraint a =>
  Inline a where
  emDash ::           Doc a
  str    :: String -> Doc a
  str = Doc . fromString
\end{lstlisting}
\captionof{figure}{\label{Second_Step_FT}
Second Step FT-encoding}
\end{figure}

The type classes look basically like a GADT-encoding where all recursive
occurrences and the return-type are parametrized over.

The observers will now be instances of theses type classes. The reader might
notice that we cannot use the same carrier type for different interpretations of
our AST — otherwise we would get overlapping instances. This can be quite easily
solved by wrapping the carrier type into a \texttt{newtype} and add or derive the
needed instances for it. In our case \texttt{Markdown} is simply a \texttt{newtype} of
\texttt{String}. Therefore the instances for \texttt{IsString} and \texttt{Monoid} are
straightforward to implement. [ Add information, on why we need \texttt{Monoid} ]

\begin{lstlisting}
instance Block CommonMark where
  paragraph     = mconcat
  bulletList    = addLineBreak . mconcat . map (mappend "\n- ")
  heading level = addLineBreak . mappend (mconcat $ replicate level "#") . mconcat

addLineBreak :: DocConstraint doc => doc -> doc
addLineBreak text = text `mappend` "\n"
\end{lstlisting}

\clearpage

Let's see how our example from above looks in our new encoding:

\begin{lstlisting}
groceryList
  = [ heading 1  [str "Grocery list"]
    , bulletList [ paragraph [str "1 Banana"]]
                 , paragraph [str "2 ", emph [str "fresh"], str " Apples"] ]
\end{lstlisting}

[ Write something about \texttt{NoMonomorphismRestriction} ]

As before, we can automate the injection of \texttt{String} into our encoding by using
the \texttt{OverloadedStrings} language pragma. We do this be adding a constraint on
the type classes, so every output format must have an \texttt{IsString} instance.

Interestingly \texttt{Doc} has now no dependency on \texttt{Inline} anymore. In a way this is
not ideal, since we can now construct the following:

\begin{lstlisting}
badHeading = [ heading 1  [ heading 2 [str "Headingception!!"] ] ]
\end{lstlisting}

As noted above, we lost the distinction between \texttt{Doc} and \texttt{Inline}. But we also
gained something — \texttt{Doc} can now be used without \texttt{Inline} and we can now also
add new nodes without changing our original data types:

\begin{lstlisting}
class IsString a => MoreStyles a where
  strong :: [a] -> a
  strikethrough :: [a] -> a
\end{lstlisting}

Not only can we now mix those node types at will, but the type of an expression
will reflect which type classes (i.e. algebras) we used for constructing it:

\begin{lstlisting}
stylishText :: (Inline a, MoreStyles a) => a
stylishText = strong [str "Green Tea keeps me awake"]
\end{lstlisting}

That is why the type system can now statically tell us whether we can evaluate
\texttt{stylishText} to a particular type. If we wanted to evaluate an expression, that
uses constructors that belong to a type class \texttt{X} and we would want to evaluate
the expression to some carrier type \texttt{C}, \texttt{C} has to be instance of \texttt{X}. Since
this is a static property, it can be decided at compile time.


\subsection{Recover Context Awareness}
\label{sec:org5ba4b2b}

To regain the context awareness of the Pandoc encoding, we add another field
\texttt{ctx} to our \texttt{Doc} wrapper \ref{ContextWrapper}. The \texttt{ctx} is a
phantom/proxy (?) type and with its help, we can specify in which context a
constructor can be used.

As shown before, the first \emph{Final Tagless encoding} had the disadvantage, that
we could construct a heading inside another heading. To prohibit this, the
\texttt{heading} constructor has the following context-aware definition:

\begin{lstlisting}
heading :: Int -> [DocWithCtx InlineCtx doc] -> DocWithCtx BlockCtx doc
\end{lstlisting}

The type signature states, that the function expects a \texttt{DocWithCtx}-wrapper in
the \texttt{InlineCtx}-context and returns a wrapper in the \texttt{BlockCtx}-context. With
this refined signature a heading inside a heading will be rejected by the type
system.

The set of available contexts should be defined generously, since all
independent extensions of the AST should agree on them. This is obviously are
restriction — but one that might be very valuable.

It is still possible to create context independent constructors. This can be
achieved by parametrizing over the context:

\begin{lstlisting}
qed :: DocWithCtx ctx doc
\end{lstlisting}

\begin{figure}[t]
\begin{lstlisting}
newtype DocWithCtx ctx doc = DocWithCtx doc
\end{lstlisting}
\captionof{figure}{\label{ContextWrapper}
Context-aware wrapper}
\end{figure}
\end{document}